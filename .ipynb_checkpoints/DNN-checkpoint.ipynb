{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Glottal.csv\")\n",
    "test  = pd.read_csv(\"Glottal.csv\")\n",
    "train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AQ_kurt</th>\n",
       "      <th>AQ_max</th>\n",
       "      <th>AQ_mean</th>\n",
       "      <th>AQ_median</th>\n",
       "      <th>AQ_min</th>\n",
       "      <th>AQ_skew</th>\n",
       "      <th>AQ_std</th>\n",
       "      <th>ClQ_kurt</th>\n",
       "      <th>ClQ_max</th>\n",
       "      <th>...</th>\n",
       "      <th>SQ1_std</th>\n",
       "      <th>SQ2_kurt</th>\n",
       "      <th>SQ2_max</th>\n",
       "      <th>SQ2_mean</th>\n",
       "      <th>SQ2_median</th>\n",
       "      <th>SQ2_min</th>\n",
       "      <th>SQ2_skew</th>\n",
       "      <th>SQ2_std</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.125019</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.399345</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-1.513942</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.308816</td>\n",
       "      <td>2.674824</td>\n",
       "      <td>1.157275</td>\n",
       "      <td>1.006275</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.952797</td>\n",
       "      <td>0.536728</td>\n",
       "      <td>D21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>D41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>D62</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.030347</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.182928</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.023530</td>\n",
       "      <td>0.869753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185508</td>\n",
       "      <td>35.373686</td>\n",
       "      <td>8.356877</td>\n",
       "      <td>0.872556</td>\n",
       "      <td>0.715124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.312221</td>\n",
       "      <td>0.945553</td>\n",
       "      <td>D26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.485704</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.101187</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.931441</td>\n",
       "      <td>0.839397</td>\n",
       "      <td>...</td>\n",
       "      <td>2.236482</td>\n",
       "      <td>18.286592</td>\n",
       "      <td>6.931799</td>\n",
       "      <td>0.688371</td>\n",
       "      <td>0.341031</td>\n",
       "      <td>0.084272</td>\n",
       "      <td>4.242434</td>\n",
       "      <td>1.524225</td>\n",
       "      <td>D28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   AQ_kurt    AQ_max   AQ_mean  AQ_median    AQ_min   AQ_skew  \\\n",
       "0           0 -1.125019  0.001362  0.000734   0.000578  0.000025  0.399345   \n",
       "1           1  0.000000  0.000273  0.000273   0.000273  0.000273  0.000000   \n",
       "2           2  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "3           3 -1.030347  0.001417  0.000791   0.000885  0.000069 -0.182928   \n",
       "4           4 -0.485704  0.000403  0.000215   0.000237  0.000046  0.101187   \n",
       "\n",
       "     AQ_std  ClQ_kurt   ClQ_max  ...   SQ1_std   SQ2_kurt   SQ2_max  SQ2_mean  \\\n",
       "0  0.000339 -1.513942  0.635115  ...  0.675402   0.308816  2.674824  1.157275   \n",
       "1  0.000000  0.000000  0.212901  ...  0.000000   0.000000  2.212919  2.212919   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000   0.000000  0.000000  0.000000   \n",
       "3  0.000360 -0.023530  0.869753  ...  1.185508  35.373686  8.356877  0.872556   \n",
       "4  0.000095 -0.931441  0.839397  ...  2.236482  18.286592  6.931799  0.688371   \n",
       "\n",
       "   SQ2_median   SQ2_min  SQ2_skew   SQ2_std  filename  label  \n",
       "0    1.006275  0.075223  0.952797  0.536728       D21    1.0  \n",
       "1    2.212919  2.212919  0.000000  0.000000       D41    1.0  \n",
       "2    0.000000  0.000000  0.000000  0.000000       D62    1.0  \n",
       "3    0.715124  0.000000  5.312221  0.945553       D26    1.0  \n",
       "4    0.341031  0.084272  4.242434  1.524225       D28    1.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train.columns.tolist()\n",
    "\n",
    "features = [f for f in filter(lambda x: x not in ['label', 'frameTime','filename'], columns)]\n",
    "target = ['label']\n",
    "\n",
    "feature_df = train[features]\n",
    "\n",
    "X_train = np.asarray(feature_df.values)\n",
    "\n",
    "y_train = np.asarray(train['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "y_train= label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin Ram\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=67, units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Ashwin Ram\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Ashwin Ram\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#initialising the Aritificial Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "#adding the input layer and first hidden layer\n",
    "classifier.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu',input_dim=67))\n",
    "\n",
    "#adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu'))\n",
    "\n",
    "#adding the output layer\n",
    "classifier.add(Dense(output_dim = 1,init = 'uniform',activation = 'sigmoid'))\n",
    "\n",
    "#compling the Artificial neural network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin Ram\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 1s 8ms/step - loss: 0.6922 - acc: 0.4959\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 0s 560us/step - loss: 0.6891 - acc: 0.4959\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 0s 519us/step - loss: 0.6814 - acc: 0.5620\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 0s 478us/step - loss: 0.6649 - acc: 0.6860\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 0s 462us/step - loss: 0.6396 - acc: 0.7190\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 0s 445us/step - loss: 0.6097 - acc: 0.7107\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 0s 429us/step - loss: 0.5773 - acc: 0.8099\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 0s 437us/step - loss: 0.5470 - acc: 0.8430\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 0s 437us/step - loss: 0.5208 - acc: 0.8264\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 0s 478us/step - loss: 0.4882 - acc: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fda782828>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test,(-1,67,1))\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49382716049382713"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Glottal.csv\")\n",
    "test  = pd.read_csv(\"Glottal.csv\")\n",
    "train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AQ_kurt</th>\n",
       "      <th>AQ_max</th>\n",
       "      <th>AQ_mean</th>\n",
       "      <th>AQ_median</th>\n",
       "      <th>AQ_min</th>\n",
       "      <th>AQ_skew</th>\n",
       "      <th>AQ_std</th>\n",
       "      <th>ClQ_kurt</th>\n",
       "      <th>ClQ_max</th>\n",
       "      <th>...</th>\n",
       "      <th>SQ1_std</th>\n",
       "      <th>SQ2_kurt</th>\n",
       "      <th>SQ2_max</th>\n",
       "      <th>SQ2_mean</th>\n",
       "      <th>SQ2_median</th>\n",
       "      <th>SQ2_min</th>\n",
       "      <th>SQ2_skew</th>\n",
       "      <th>SQ2_std</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.125019</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.399345</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-1.513942</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.308816</td>\n",
       "      <td>2.674824</td>\n",
       "      <td>1.157275</td>\n",
       "      <td>1.006275</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.952797</td>\n",
       "      <td>0.536728</td>\n",
       "      <td>D21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>2.212919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>D41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>D62</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.030347</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.182928</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.023530</td>\n",
       "      <td>0.869753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185508</td>\n",
       "      <td>35.373686</td>\n",
       "      <td>8.356877</td>\n",
       "      <td>0.872556</td>\n",
       "      <td>0.715124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.312221</td>\n",
       "      <td>0.945553</td>\n",
       "      <td>D26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.485704</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.101187</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.931441</td>\n",
       "      <td>0.839397</td>\n",
       "      <td>...</td>\n",
       "      <td>2.236482</td>\n",
       "      <td>18.286592</td>\n",
       "      <td>6.931799</td>\n",
       "      <td>0.688371</td>\n",
       "      <td>0.341031</td>\n",
       "      <td>0.084272</td>\n",
       "      <td>4.242434</td>\n",
       "      <td>1.524225</td>\n",
       "      <td>D28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   AQ_kurt    AQ_max   AQ_mean  AQ_median    AQ_min   AQ_skew  \\\n",
       "0           0 -1.125019  0.001362  0.000734   0.000578  0.000025  0.399345   \n",
       "1           1  0.000000  0.000273  0.000273   0.000273  0.000273  0.000000   \n",
       "2           2  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "3           3 -1.030347  0.001417  0.000791   0.000885  0.000069 -0.182928   \n",
       "4           4 -0.485704  0.000403  0.000215   0.000237  0.000046  0.101187   \n",
       "\n",
       "     AQ_std  ClQ_kurt   ClQ_max  ...   SQ1_std   SQ2_kurt   SQ2_max  SQ2_mean  \\\n",
       "0  0.000339 -1.513942  0.635115  ...  0.675402   0.308816  2.674824  1.157275   \n",
       "1  0.000000  0.000000  0.212901  ...  0.000000   0.000000  2.212919  2.212919   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000   0.000000  0.000000  0.000000   \n",
       "3  0.000360 -0.023530  0.869753  ...  1.185508  35.373686  8.356877  0.872556   \n",
       "4  0.000095 -0.931441  0.839397  ...  2.236482  18.286592  6.931799  0.688371   \n",
       "\n",
       "   SQ2_median   SQ2_min  SQ2_skew   SQ2_std  filename  label  \n",
       "0    1.006275  0.075223  0.952797  0.536728       D21    1.0  \n",
       "1    2.212919  2.212919  0.000000  0.000000       D41    1.0  \n",
       "2    0.000000  0.000000  0.000000  0.000000       D62    1.0  \n",
       "3    0.715124  0.000000  5.312221  0.945553       D26    1.0  \n",
       "4    0.341031  0.084272  4.242434  1.524225       D28    1.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = train.columns.tolist()\n",
    "\n",
    "features = [f for f in filter(lambda x: x not in ['label', 'frameTime','filename'], columns)]\n",
    "target = ['label']\n",
    "\n",
    "feature_df = train[features]\n",
    "\n",
    "X = np.asarray(feature_df.values)\n",
    "\n",
    "y = np.asarray(train['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "import keras\n",
    "model.add(keras.layers.convolutional.Convolution1D(filters=2, kernel_size=2, \n",
    "activation='relu',input_shape=(67,1)))\n",
    "model.add(keras.layers.convolutional.MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.convolutional.Convolution1D(15,kernel_size=2, activation= 'relu' ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.convolutional.MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "141/141 [==============================] - 0s 559us/step - loss: 0.1779 - acc: 0.9645\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 0s 509us/step - loss: 0.1745 - acc: 0.9433\n",
      "Epoch 3/100\n",
      " 10/141 [=>............................] - ETA: 0s - loss: 0.2684 - acc: 0.9000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin Ram\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 502us/step - loss: 0.1610 - acc: 0.9716\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 0s 481us/step - loss: 0.1524 - acc: 0.9716\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 0s 481us/step - loss: 0.1472 - acc: 0.9574\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 0s 552us/step - loss: 0.1460 - acc: 0.9574\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 0s 488us/step - loss: 0.1462 - acc: 0.9574\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 0s 488us/step - loss: 0.1324 - acc: 0.9645\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 0s 488us/step - loss: 0.1305 - acc: 0.9645\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.1309 - acc: 0.9574\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.1200 - acc: 0.9716\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 0s 573us/step - loss: 0.1218 - acc: 0.9645\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 0s 488us/step - loss: 0.1223 - acc: 0.9574\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 0s 523us/step - loss: 0.1131 - acc: 0.9645\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 0s 552us/step - loss: 0.1171 - acc: 0.9574\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 0s 523us/step - loss: 0.1087 - acc: 0.9645\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.1122 - acc: 0.9645\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.1060 - acc: 0.9645\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.1032 - acc: 0.9645\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.1061 - acc: 0.9645\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.1020 - acc: 0.9716\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.1711 - acc: 0.9362\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.1292 - acc: 0.9433\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.1010 - acc: 0.9645\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.1114 - acc: 0.9574\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0948 - acc: 0.9645\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 0s 495us/step - loss: 0.0973 - acc: 0.9645\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0949 - acc: 0.9574\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0958 - acc: 0.9645\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0932 - acc: 0.9574\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 0s 552us/step - loss: 0.0929 - acc: 0.9645\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 0s 509us/step - loss: 0.0921 - acc: 0.9645\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 0s 566us/step - loss: 0.0918 - acc: 0.9645\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 0s 545us/step - loss: 0.0929 - acc: 0.9645\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0895 - acc: 0.9716\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0889 - acc: 0.9645\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 0s 403us/step - loss: 0.0928 - acc: 0.9645\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0880 - acc: 0.9574\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0884 - acc: 0.9716\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0837 - acc: 0.9645\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0826 - acc: 0.969 - 0s 481us/step - loss: 0.0857 - acc: 0.9645\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 0s 502us/step - loss: 0.0861 - acc: 0.9645\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 0s 439us/step - loss: 0.0830 - acc: 0.9645\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0947 - acc: 0.9574\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0837 - acc: 0.9645\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0849 - acc: 0.9787\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0828 - acc: 0.9645\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0790 - acc: 0.9645\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 0s 538us/step - loss: 0.0874 - acc: 0.9645\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 0s 566us/step - loss: 0.0773 - acc: 0.9645\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 0s 488us/step - loss: 0.0820 - acc: 0.9645\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 0s 552us/step - loss: 0.0754 - acc: 0.9645\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 0s 439us/step - loss: 0.0777 - acc: 0.9716\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0799 - acc: 0.9645\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 0s 446us/step - loss: 0.1245 - acc: 0.9574\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0936 - acc: 0.9504\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0765 - acc: 0.9645\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0844 - acc: 0.9574\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0711 - acc: 0.9716\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0841 - acc: 0.9787\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0718 - acc: 0.9858\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0697 - acc: 0.9645\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 0s 495us/step - loss: 0.0700 - acc: 0.9716\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 0s 467us/step - loss: 0.0697 - acc: 0.9645\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0688 - acc: 0.9716\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 0s 446us/step - loss: 0.0685 - acc: 0.9716\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 0s 481us/step - loss: 0.0668 - acc: 0.9716\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 0s 566us/step - loss: 0.0711 - acc: 0.9574\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 0s 552us/step - loss: 0.0665 - acc: 0.9716\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 0s 516us/step - loss: 0.0656 - acc: 0.9716\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 0s 566us/step - loss: 0.0672 - acc: 0.9716\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 0s 545us/step - loss: 0.0629 - acc: 0.9716\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 0s 516us/step - loss: 0.0651 - acc: 0.9716\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 0s 523us/step - loss: 0.0651 - acc: 0.9716\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 0s 516us/step - loss: 0.0652 - acc: 0.9716\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 0s 502us/step - loss: 0.0642 - acc: 0.9787\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 0s 523us/step - loss: 0.0636 - acc: 0.9716\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 0s 516us/step - loss: 0.0608 - acc: 0.9716\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 0s 530us/step - loss: 0.0606 - acc: 0.9787\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 0s 516us/step - loss: 0.0623 - acc: 0.9716\n",
      "Epoch 81/100\n",
      "141/141 [==============================] - 0s 523us/step - loss: 0.0599 - acc: 0.9716\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 0s 516us/step - loss: 0.0604 - acc: 0.9716\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 0s 495us/step - loss: 0.0590 - acc: 0.9787\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 0s 538us/step - loss: 0.0588 - acc: 0.9716\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 0s 594us/step - loss: 0.0636 - acc: 0.9858\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 0s 559us/step - loss: 0.0628 - acc: 0.9716\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0553 - acc: 0.9787\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 0s 446us/step - loss: 0.0557 - acc: 0.9929\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 0s 424us/step - loss: 0.0577 - acc: 0.9787\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0559 - acc: 0.9858\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0540 - acc: 0.9929\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 0s 502us/step - loss: 0.0608 - acc: 0.9787\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 0s 474us/step - loss: 0.0528 - acc: 0.9858\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 0s 481us/step - loss: 0.0568 - acc: 0.9858\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 0s 495us/step - loss: 0.0526 - acc: 0.9858\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 0s 460us/step - loss: 0.0521 - acc: 0.9858\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 0s 453us/step - loss: 0.0541 - acc: 0.9716\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 0s 445us/step - loss: 0.0518 - acc: 0.9858\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 0s 502us/step - loss: 0.0518 - acc: 0.9929\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 0s 523us/step - loss: 0.0490 - acc: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fa32bd438>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test,(-1,67,1))\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47540983606557374"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "63476874-fa36-435a-a3b9-898b5473e28f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
